{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mBdKGD39S58T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torchvision  \n",
    "import subprocess\n",
    "import cv2\n",
    "import ffmpeg\n",
    "import os\n",
    "import os.path as osp\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CSFF51DrTFQb"
   },
   "outputs": [],
   "source": [
    "VID_PATH = \"../../data/extracted_videos/\"\n",
    "VID_PATH_OG = \"../../data/videos_new/\"\n",
    "LABEL_FILE = \"../../data/data.npy\"\n",
    "PROCESSED_PATH = \"../../data_temp/processed/\"\n",
    "DATA_SAVE_PATH = \"../../data_temp/labeled_videos/\"\n",
    "MODELS_PATHS = \"./models/\"\n",
    "# LABEL_PATH = '../../data/labels/'\n",
    "FRAME_RATE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iUspG4_on3ax"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Preprocess video data.\n",
    "\"\"\"\n",
    "def label_map(lab):\n",
    "    if(lab == 0):\n",
    "        return 2\n",
    "    elif(lab == -1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def get_all_files_from_dir(directory, vids = False):\n",
    "    file_paths = []\n",
    "    print(directory)\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            # print(files)\n",
    "            if(vids):\n",
    "                file_paths += [os.path.join(root, x,x+\".mp4\") for x in dirs]\n",
    "            else:\n",
    "                file_paths += [os.path.join(root, x) for x in files]\n",
    "        return sorted(file_paths)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "def process_video(video_file, labels):\n",
    "    video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "    vidcap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    ctr = 0\n",
    "    video_frames = []\n",
    "    video_labels = []\n",
    "    \n",
    "    hasFrames,image = vidcap.read()\n",
    "\n",
    "    while (hasFrames):\n",
    "        save_file_name = video_filename + \"_\" + str(ctr) + \".npy\"\n",
    "        np.save(osp.join(PROCESSED_PATH, save_file_name), image)  \n",
    "        label_ts = vidcap.get(cv2.CAP_PROP_POS_MSEC) + 1000 #take 1 sec ahead labels \n",
    "        label_ts = label_ts - (label_ts%100)\n",
    "        if(label_ts not in labels.keys()):\n",
    "            print(label_ts)\n",
    "            hasFrames,image = vidcap.read()\n",
    "            continue\n",
    "        label = labels[label_ts]\n",
    "        video_labels.append(label_map(label))\n",
    "        video_frames.append(save_file_name)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        ctr += 1\n",
    "        \n",
    "    df = pd.DataFrame({'frames': video_frames, 'labels': video_labels})\n",
    "    df.to_csv(osp.join(DATA_SAVE_PATH,video_filename+\".csv\"), index=None)\n",
    "\n",
    "    print(\"After processing:\")\n",
    "    print(\"Number of frames labelled: \", ctr)\n",
    "    \n",
    "def preprocess():\n",
    "    f = np.load(LABEL_FILE, allow_pickle = True)\n",
    "    for video_file in get_all_files_from_dir(VID_PATH):\n",
    "        video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "        labels = f[video_filename]['Sensor']['direction_label']['direction']\n",
    "        process_video(video_file, labels)\n",
    "        print(\"Finished processing \", video_file)\n",
    "        \n",
    "def process_videos():\n",
    "    fp = get_all_files_from_dir(VID_PATH_OG, vids=True)\n",
    "    print(fp)\n",
    "    for fl in fp:\n",
    "        video_filename = fl.split('/')[-1]\n",
    "        ffmpeg.input(fl).filter('fps', fps=10, round='up').output(VID_PATH+video_filename).run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/extracted_videos/\n",
      "16200.0\n",
      "16300.0\n",
      "16400.0\n",
      "16500.0\n",
      "16600.0\n",
      "16700.0\n",
      "16800.0\n",
      "16900.0\n",
      "17000.0\n",
      "17100.0\n",
      "After processing:\n",
      "Number of frames labelled:  152\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:06:23.406Z.mp4\n",
      "27400.0\n",
      "27500.0\n",
      "27600.0\n",
      "27700.0\n",
      "27800.0\n",
      "27900.0\n",
      "28000.0\n",
      "28100.0\n",
      "28200.0\n",
      "28300.0\n",
      "After processing:\n",
      "Number of frames labelled:  264\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:07:08.854Z.mp4\n",
      "18200.0\n",
      "18300.0\n",
      "18400.0\n",
      "18500.0\n",
      "18600.0\n",
      "18700.0\n",
      "18800.0\n",
      "18900.0\n",
      "19000.0\n",
      "19100.0\n",
      "19200.0\n",
      "After processing:\n",
      "Number of frames labelled:  172\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:07:57.983Z.mp4\n",
      "51800.0\n",
      "51900.0\n",
      "52000.0\n",
      "52100.0\n",
      "52200.0\n",
      "52300.0\n",
      "52400.0\n",
      "52500.0\n",
      "52600.0\n",
      "52700.0\n",
      "52800.0\n",
      "After processing:\n",
      "Number of frames labelled:  508\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:08:26.648Z.mp4\n",
      "14300.0\n",
      "14400.0\n",
      "14500.0\n",
      "14600.0\n",
      "14700.0\n",
      "14800.0\n",
      "14900.0\n",
      "15000.0\n",
      "15100.0\n",
      "15200.0\n",
      "15300.0\n",
      "After processing:\n",
      "Number of frames labelled:  133\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:10:36.407Z.mp4\n",
      "35900.0\n",
      "36000.0\n",
      "36100.0\n",
      "36200.0\n",
      "36300.0\n",
      "36400.0\n",
      "36500.0\n",
      "36600.0\n",
      "36700.0\n",
      "36800.0\n",
      "36900.0\n",
      "After processing:\n",
      "Number of frames labelled:  349\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:11:48.827Z.mp4\n",
      "6700.0\n",
      "6800.0\n",
      "6900.0\n",
      "7000.0\n",
      "7100.0\n",
      "7200.0\n",
      "7300.0\n",
      "7400.0\n",
      "7500.0\n",
      "7600.0\n",
      "7700.0\n",
      "After processing:\n",
      "Number of frames labelled:  57\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:12:38.748Z.mp4\n",
      "24000.0\n",
      "24100.0\n",
      "24200.0\n",
      "24300.0\n",
      "24400.0\n",
      "24500.0\n",
      "24600.0\n",
      "24700.0\n",
      "24800.0\n",
      "24900.0\n",
      "25000.0\n",
      "After processing:\n",
      "Number of frames labelled:  230\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:12:56.605Z.mp4\n",
      "23300.0\n",
      "23400.0\n",
      "23500.0\n",
      "23600.0\n",
      "23700.0\n",
      "23800.0\n",
      "23900.0\n",
      "24000.0\n",
      "24100.0\n",
      "24200.0\n",
      "24300.0\n",
      "After processing:\n",
      "Number of frames labelled:  223\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:13:42.852Z.mp4\n",
      "86400.0\n",
      "86500.0\n",
      "86600.0\n",
      "86700.0\n",
      "86800.0\n",
      "86900.0\n",
      "87000.0\n",
      "87100.0\n",
      "87200.0\n",
      "87300.0\n",
      "87400.0\n",
      "87500.0\n",
      "After processing:\n",
      "Number of frames labelled:  854\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:14:28.350Z.mp4\n",
      "13500.0\n",
      "13600.0\n",
      "13700.0\n",
      "13800.0\n",
      "13900.0\n",
      "14000.0\n",
      "14100.0\n",
      "14200.0\n",
      "14300.0\n",
      "14400.0\n",
      "14500.0\n",
      "After processing:\n",
      "Number of frames labelled:  125\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:16:48.983Z.mp4\n",
      "18700.0\n",
      "18800.0\n",
      "18900.0\n",
      "19000.0\n",
      "19100.0\n",
      "19200.0\n",
      "19300.0\n",
      "19400.0\n",
      "19500.0\n",
      "19600.0\n",
      "After processing:\n",
      "Number of frames labelled:  177\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:17:19.405Z.mp4\n",
      "17500.0\n",
      "17600.0\n",
      "17700.0\n",
      "17800.0\n",
      "17900.0\n",
      "18000.0\n",
      "18100.0\n",
      "18200.0\n",
      "18300.0\n",
      "18400.0\n",
      "18500.0\n",
      "18600.0\n",
      "After processing:\n",
      "Number of frames labelled:  165\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:18:27.292Z.mp4\n",
      "10100.0\n",
      "10200.0\n",
      "10300.0\n",
      "10400.0\n",
      "10500.0\n",
      "10600.0\n",
      "10700.0\n",
      "10800.0\n",
      "10900.0\n",
      "11000.0\n",
      "11100.0\n",
      "11200.0\n",
      "After processing:\n",
      "Number of frames labelled:  91\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:19:01.849Z.mp4\n",
      "29100.0\n",
      "29200.0\n",
      "29300.0\n",
      "29400.0\n",
      "29500.0\n",
      "29600.0\n",
      "29700.0\n",
      "29800.0\n",
      "29900.0\n",
      "30000.0\n",
      "After processing:\n",
      "Number of frames labelled:  281\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:19:26.012Z.mp4\n",
      "54800.0\n",
      "54900.0\n",
      "55000.0\n",
      "55100.0\n",
      "55200.0\n",
      "55300.0\n",
      "55400.0\n",
      "55500.0\n",
      "55600.0\n",
      "55700.0\n",
      "55800.0\n",
      "After processing:\n",
      "Number of frames labelled:  538\n",
      "Finished processing  ../../data/extracted_videos/2022-04-04T16:20:59.483Z.mp4\n"
     ]
    }
   ],
   "source": [
    "### preprocess videos\n",
    "# process_videos()\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e5gsuYg0EDMN"
   },
   "outputs": [],
   "source": [
    "BATCH = 64\n",
    "SEQUENCE_LENGTH = 10\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, index, optim = False):\n",
    "    if not os.path.exists(MODELS_PATHS+'/attempt_7_frames_resnet34_new_data'):\n",
    "        os.mkdir(MODELS_PATHS+'/attempt_7_frames_resnet34_new_data')\n",
    "    if(optim):\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt_7_frames_resnet34_new_data'+'/optimizer_params_{:08d}.pth'.format(index))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt_7_frames_resnet34_new_data'+'/model_params_{:08d}.pth'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    \"\"\"\n",
    "    Container for ResNet50 s.t. it can be used for metric learning.\n",
    "    The Network has been broken down to allow for higher modularity, if one wishes\n",
    "    to target specific layers/blocks directly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fixconvs=False, pretrained=True):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=pretrained)\n",
    "        if fixconvs:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.regressor = nn.Linear(self.model.fc.in_features, 3)\n",
    "        self.dropout = torch.nn.Dropout(p=0.05)\n",
    "        self.model = torch.nn.Sequential(*(list(self.model.children())[:-1]))\n",
    "        # model.fc.weight.requires_grad = True\n",
    "        # model.fc.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.regressor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, x, y, transforms, base_path):\n",
    "        self.transforms = transforms\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        # self.seq_len = seq_len\n",
    "        self.base_path = base_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq_filename = self.X[idx]\n",
    "        try:\n",
    "            frame = np.load(osp.join(self.base_path,seq_filename), allow_pickle=True)\n",
    "            frame = (frame - frame.min())/(frame.max() - frame.min())\n",
    "            frame = self.transforms(frame)\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(\"Error occured while loading frame: \", ex)\n",
    "            frame = torch.zeros((CHANNELS, HEIGHT, WIDTH))\n",
    "        \n",
    "        return frame, self.y[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tt_split(data_folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filename in os.listdir(data_folder):\n",
    "        if(filename[-3:]==\"csv\"):\n",
    "            df = pd.read_csv(osp.join(data_folder,filename))\n",
    "            X.append(df['frames'])\n",
    "            y.append(df['labels'])\n",
    "    \n",
    "    X = pd.concat(X)\n",
    "    # print(X.head())\n",
    "    X.reset_index(drop=True,inplace=True)\n",
    "    X = X.to_numpy()\n",
    "\n",
    "    \n",
    "    y = pd.concat(y)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    y = y.to_numpy()\n",
    "            \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX1zg-g3In-9",
    "outputId": "aff9d5b2-0a91-4ecc-b6b2-9beaed1448aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# train_transforms = [ttf.ToTensor(), transforms.Resize((HEIGHT, WIDTH)), transforms.ColorJitter(), transforms.RandomRotation(10), transforms.GaussianBlur(3)]\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_tt_split(DATA_SAVE_PATH)\n",
    "train_dataset = FrameDataset(X_train, y_train, transforms=train_transforms, base_path = PROCESSED_PATH)\n",
    "val_dataset = FrameDataset(X_test, y_test, transforms=val_transforms, base_path = PROCESSED_PATH)\n",
    "\n",
    "train_args = dict(shuffle=True, batch_size=BATCH, num_workers=1, pin_memory=True, drop_last=False) if cuda else dict(shuffle=True, batch_size=BATCH, drop_last=False)\n",
    "train_loader = DataLoader(train_dataset, **train_args)\n",
    "\n",
    "val_args = dict(shuffle=False, batch_size=BATCH, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=BATCH, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, **val_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tgnvcg7a8hHp",
    "outputId": "a4373e9f-1c67-477f-d9a7-4f3088d160cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3455\n",
      "864\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, val_dataset, model):\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_num_correct = 0\n",
    "   \n",
    "    for i, (vx, vy) in enumerate(val_loader):\n",
    "      \n",
    "        vx = vx.float().to(device)\n",
    "        vy = vy.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(vx)\n",
    "            del vx\n",
    "\n",
    "        val_num_correct += int((torch.argmax(outputs, axis=1) == vy).sum())\n",
    "        del outputs\n",
    "        # break\n",
    "    \n",
    "\n",
    "    print(\"Validation: {:.04f}%\".format(100 * val_num_correct / (len(val_dataset))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sl89a6wJMJEA",
    "outputId": "dbe36a2f-f49a-44f4-e87e-ddb88ab225bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752a4135d73b4f4e842f561df35b7328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 0.005 #changed from 0.01\n",
    "epochs = 25\n",
    "lamda = 1e-3  #L2 regularization #changed from 1e-4\n",
    "num_classes = 3\n",
    "convlstm_hidden = 128\n",
    "num_conv_lstm_layers = 2\n",
    "\n",
    "model = ResNet18()\n",
    "model.load_state_dict(torch.load('./models/attempt_7_frames_resnet34_new_data/model_params_00000003.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=lamda, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lamda)\n",
    "optimizer.load_state_dict(torch.load('./models/attempt_7_frames_resnet34_new_data/optimizer_params_00000003.pth'))\n",
    "\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = lr\n",
    "    # g['weight_decay']= lamda\n",
    "    \n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "dhrrwnCikFAG",
    "outputId": "fb495db9-61a9-4511-b30c-ea4144f8004e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: Train Acc 80.1737%, Train Loss 0.5839, Learning Rate 0.0050\n",
      "Validation: 80.3241%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: Train Acc 81.0999%, Train Loss 0.5218, Learning Rate 0.0049\n",
      "Validation: 81.2500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: Train Acc 81.2446%, Train Loss 0.5001, Learning Rate 0.0048\n",
      "Validation: 54.5139%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: Train Acc 83.7337%, Train Loss 0.4287, Learning Rate 0.0047\n",
      "Validation: 82.4074%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: Train Acc 83.9942%, Train Loss 0.4207, Learning Rate 0.0045\n",
      "Validation: 74.7685%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: Train Acc 86.1360%, Train Loss 0.3628, Learning Rate 0.0043\n",
      "Validation: 80.9028%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  98%|██████████████████████████████████▎| 53/54 [03:55<00:04,  4.48s/it, acc=87.5000%, loss=0.3299, lr=0.0041, num_correct=2968]"
     ]
    }
   ],
   "source": [
    "for epoch in range(4,epochs):\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
    "\n",
    "    num_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "       \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.float().to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(x)\n",
    "            del x\n",
    "            loss = criterion(outputs.view(-1,num_classes), y.long().view(-1))\n",
    "\n",
    "        # print(outputs.shape)\n",
    "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
    "        del outputs\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * BATCH)),\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            num_correct=num_correct,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        batch_bar.update() # Update tqdm bar\n",
    "        # break\n",
    "        \n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    print(\"Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
    "        epoch + 1,\n",
    "        epochs,\n",
    "        100 * num_correct / (len(train_dataset)),\n",
    "        float(total_loss / len(train_loader)),\n",
    "        float(optimizer.param_groups[0]['lr'])))\n",
    "    \n",
    "    save(model, epoch)\n",
    "    save(optimizer, epoch, optim=True)\n",
    "    \n",
    "    validate(val_loader, val_dataset, model)\n",
    "    \n",
    "batch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AI_Guide_Dog_Training_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
