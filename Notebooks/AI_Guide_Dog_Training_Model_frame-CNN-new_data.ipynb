{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mBdKGD39S58T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torchvision  \n",
    "import subprocess\n",
    "import cv2\n",
    "# import ffmpeg\n",
    "import os\n",
    "import os.path as osp\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CSFF51DrTFQb"
   },
   "outputs": [],
   "source": [
    "VID_PATH = \"../../data/extracted_videos/\"\n",
    "VID_PATH_OG = \"../../data/videos_new/\"\n",
    "LABEL_FILE = \"../../data/data.npy\"\n",
    "PROCESSED_PATH = \"../data_temp/processed/\"\n",
    "DATA_SAVE_PATH = \"../data_temp/labeled_videos/\"\n",
    "MODELS_PATHS = \"./models/\"\n",
    "# LABEL_PATH = '../../data/labels/'\n",
    "FRAME_RATE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iUspG4_on3ax"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Preprocess video data.\n",
    "\"\"\"\n",
    "def label_map(lab):\n",
    "    if(lab == 0):\n",
    "        return 2\n",
    "    elif(lab == -1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def get_all_files_from_dir(directory, vids = False):\n",
    "    file_paths = []\n",
    "    print(directory)\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            # print(files)\n",
    "            if(vids):\n",
    "                file_paths += [os.path.join(root, x,x+\".mp4\") for x in dirs]\n",
    "            else:\n",
    "                file_paths += [os.path.join(root, x) for x in files]\n",
    "        return sorted(file_paths)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "def process_video(video_file, labels):\n",
    "    video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "    vidcap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    ctr = 0\n",
    "    video_frames = []\n",
    "    video_labels = []\n",
    "    \n",
    "    hasFrames,image = vidcap.read()\n",
    "\n",
    "    while (hasFrames):\n",
    "        save_file_name = video_filename + \"_\" + str(ctr) + \".npy\"\n",
    "        np.save(osp.join(PROCESSED_PATH, save_file_name), image)  \n",
    "        label_ts = vidcap.get(cv2.CAP_PROP_POS_MSEC) + 1000 #take 1 sec ahead labels \n",
    "        label_ts = label_ts - (label_ts%100)\n",
    "        if(label_ts not in labels.keys()):\n",
    "            print(label_ts)\n",
    "            hasFrames,image = vidcap.read()\n",
    "            continue\n",
    "        label = labels[label_ts]\n",
    "        video_labels.append(label_map(label))\n",
    "        video_frames.append(save_file_name)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        ctr += 1\n",
    "        \n",
    "    df = pd.DataFrame({'frames': video_frames, 'labels': video_labels})\n",
    "    df.to_csv(osp.join(DATA_SAVE_PATH,video_filename+\".csv\"), index=None)\n",
    "\n",
    "    print(\"After processing:\")\n",
    "    print(\"Number of frames labelled: \", ctr)\n",
    "    \n",
    "def preprocess():\n",
    "    f = np.load(LABEL_FILE, allow_pickle = True)\n",
    "    print(f.keys())\n",
    "    for video_file in get_all_files_from_dir(VID_PATH):\n",
    "        video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "        print(video_filename)\n",
    "        if(video_filename+\".csv\" not in os.listdir(DATA_SAVE_PATH)):\n",
    "            labels = f[video_filename]['Sensor']['direction_label']['direction']\n",
    "            process_video(video_file, labels)\n",
    "            print(\"Finished processing \", video_file)\n",
    "        \n",
    "def process_videos(vid_path = VID_PATH_OG):\n",
    "    fp = get_all_files_from_dir(vid_path, vids=True)\n",
    "    print(fp)\n",
    "    for fl in fp:\n",
    "        video_filename = fl.split('/')[-1]\n",
    "        if(video_filename not in os.listdir(VID_PATH)):\n",
    "            ffmpeg.input(fl).filter('fps', fps=10, round='up').output(VID_PATH+video_filename).run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocess videos\n",
    "# process_videos()\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e5gsuYg0EDMN"
   },
   "outputs": [],
   "source": [
    "BATCH = 128\n",
    "SEQUENCE_LENGTH = 10\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, index, optim = False):\n",
    "    if not os.path.exists(MODELS_PATHS+'/attempt_8_frames_resnet18_new_data_diff_split'):\n",
    "        os.mkdir(MODELS_PATHS+'/attempt_8_frames_resnet18_new_data_diff_split')\n",
    "    if(optim):\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt_8_frames_resnet18_new_data_diff_split'+'/optimizer_params_{:08d}.pth'.format(index))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt_8_frames_resnet18_new_data_diff_split'+'/model_params_{:08d}.pth'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    \"\"\"\n",
    "    Container for ResNet50 s.t. it can be used for metric learning.\n",
    "    The Network has been broken down to allow for higher modularity, if one wishes\n",
    "    to target specific layers/blocks directly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fixconvs=False, pretrained=True):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=pretrained)\n",
    "        if fixconvs:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.regressor = nn.Linear(self.model.fc.in_features, 3)\n",
    "        self.dropout = torch.nn.Dropout(p=0.07)\n",
    "        self.model = torch.nn.Sequential(*(list(self.model.children())[:-1]))\n",
    "        # model.fc.weight.requires_grad = True\n",
    "        # model.fc.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.regressor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, x, y, transforms, base_path):\n",
    "        self.transforms = transforms\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        # self.seq_len = seq_len\n",
    "        self.base_path = base_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq_filename = self.X[idx]\n",
    "        try:\n",
    "            frame = np.load(osp.join(self.base_path,seq_filename), allow_pickle=True)\n",
    "            frame = (frame - frame.min())/(frame.max() - frame.min())\n",
    "            frame = self.transforms(frame)\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(\"Error occured while loading frame: \", ex)\n",
    "            frame = torch.zeros((CHANNELS, HEIGHT, WIDTH))\n",
    "        \n",
    "        return frame, self.y[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tt_split(data_folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filename in os.listdir(data_folder):\n",
    "        if(filename[-3:]==\"csv\"):\n",
    "            df = pd.read_csv(osp.join(data_folder,filename))\n",
    "            X.append(df['frames'].to_numpy())\n",
    "            y.append(df['labels'].to_numpy())\n",
    "    \n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    print(\"Train videos: \", len(X_train))\n",
    "    print(\"Test videos: \", len(X_test))\n",
    "    \n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    X_test = np.concatenate(X_test)\n",
    "    y_test = np.concatenate(y_test)\n",
    "    \n",
    "    f = {osp.join(data_folder,f.split('_')[0]+\".csv\") for f in X_test}\n",
    "    print(f)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX1zg-g3In-9",
    "outputId": "aff9d5b2-0a91-4ecc-b6b2-9beaed1448aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Train videos:  31\n",
      "Test videos:  8\n",
      "{'../data_temp/labeled_videos/2022-04-04T16:07:57.csv', '../data_temp/labeled_videos/2022-04-04T18:48:45.704Z.csv', '../data_temp/labeled_videos/2022-04-04T19:10:28.196Z.csv', '../data_temp/labeled_videos/2022-04-04T16:14:28.csv', '../data_temp/labeled_videos/2022-04-04T19:02:28.038Z.csv', '../data_temp/labeled_videos/2022-04-04T19:18:52.214Z.csv', '../data_temp/labeled_videos/2022-04-04T19:28:57.167Z.csv', '../data_temp/labeled_videos/2022-04-04T18:41:15.478Z.csv'}\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# train_transforms = [ttf.ToTensor(), transforms.Resize((HEIGHT, WIDTH)), transforms.ColorJitter(), transforms.RandomRotation(10), transforms.GaussianBlur(3)]\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_tt_split(DATA_SAVE_PATH)\n",
    "train_dataset = FrameDataset(X_train, y_train, transforms=train_transforms, base_path = PROCESSED_PATH)\n",
    "val_dataset = FrameDataset(X_test, y_test, transforms=val_transforms, base_path = PROCESSED_PATH)\n",
    "\n",
    "train_args = dict(shuffle=True, batch_size=BATCH, num_workers=1, pin_memory=True, drop_last=False) if cuda else dict(shuffle=True, batch_size=BATCH, drop_last=False)\n",
    "train_loader = DataLoader(train_dataset, **train_args)\n",
    "\n",
    "val_args = dict(shuffle=False, batch_size=BATCH, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=BATCH, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, **val_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tgnvcg7a8hHp",
    "outputId": "a4373e9f-1c67-477f-d9a7-4f3088d160cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10659\n",
      "3824\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, val_dataset, model):\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_num_correct = 0\n",
    "   \n",
    "    for i, (vx, vy) in enumerate(val_loader):\n",
    "      \n",
    "        vx = vx.float().to(device)\n",
    "        vy = vy.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(vx)\n",
    "            del vx\n",
    "\n",
    "        val_num_correct += int((torch.argmax(outputs, axis=1) == vy).sum())\n",
    "        del outputs\n",
    "       \n",
    "    print(\"Validation: {:.04f}%\".format(100 * val_num_correct / (len(val_dataset))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 #changed from 0.01\n",
    "epochs = 25\n",
    "lamda = 1e-2  #L2 regularization #changed from 1e-4\n",
    "num_classes = 3\n",
    "convlstm_hidden = 128\n",
    "num_conv_lstm_layers = 1\n",
    "\n",
    "model = ResNet18()\n",
    "# model.load_state_dict(torch.load('./models/attempt_8_frames_resnet18_new_data_diff_split/model_params_00000003.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=lamda, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lamda)\n",
    "# optimizer.load_state_dict(torch.load('./models/attempt_7_frames_resnet34_new_data/optimizer_params_00000003.pth'))\n",
    "\n",
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] = lr\n",
    "    # g['weight_decay']= lamda\n",
    "    \n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: Train Acc 69.0121%, Train Loss 0.8116, Learning Rate 0.0100\n",
      "Validation: 65.4027%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: Train Acc 69.1341%, Train Loss 0.7995, Learning Rate 0.0098\n",
      "Validation: 65.4027%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: Train Acc 69.1341%, Train Loss 0.7881, Learning Rate 0.0096\n",
      "Validation: 65.4027%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: Train Acc 69.4624%, Train Loss 0.7650, Learning Rate 0.0094\n",
      "Validation: 63.3368%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: Train Acc 69.8471%, Train Loss 0.7541, Learning Rate 0.0090\n",
      "Validation: 58.7082%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: Train Acc 70.8697%, Train Loss 0.7304, Learning Rate 0.0086\n",
      "Validation: 60.9571%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: Train Acc 72.2207%, Train Loss 0.7070, Learning Rate 0.0082\n",
      "Validation: 66.4749%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: Train Acc 74.2846%, Train Loss 0.6548, Learning Rate 0.0077\n",
      "Validation: 64.6967%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: Train Acc 75.6450%, Train Loss 0.6114, Learning Rate 0.0071\n",
      "Validation: 65.8211%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: Train Acc 76.8083%, Train Loss 0.5859, Learning Rate 0.0065\n",
      "Validation: 63.7814%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: Train Acc 78.5252%, Train Loss 0.5408, Learning Rate 0.0059\n",
      "Validation: 62.3169%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: Train Acc 79.2757%, Train Loss 0.5170, Learning Rate 0.0053\n",
      "Validation: 65.2458%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: Train Acc 81.8276%, Train Loss 0.4678, Learning Rate 0.0047\n",
      "Validation: 63.2322%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: Train Acc 83.4225%, Train Loss 0.4272, Learning Rate 0.0041\n",
      "Validation: 60.5649%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: Train Acc 85.7210%, Train Loss 0.3758, Learning Rate 0.0035\n",
      "Validation: 65.2981%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: Train Acc 87.1658%, Train Loss 0.3415, Learning Rate 0.0029\n",
      "Validation: 62.0554%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: Train Acc 89.4549%, Train Loss 0.2922, Learning Rate 0.0023\n",
      "Validation: 58.4205%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: Train Acc 90.6183%, Train Loss 0.2620, Learning Rate 0.0018\n",
      "Validation: 59.8588%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: Train Acc 92.4196%, Train Loss 0.2215, Learning Rate 0.0014\n",
      "Validation: 59.3881%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: Train Acc 93.2545%, Train Loss 0.2016, Learning Rate 0.0010\n",
      "Validation: 56.8776%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: Train Acc 94.3803%, Train Loss 0.1682, Learning Rate 0.0006\n",
      "Validation: 58.6820%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: Train Acc 95.4123%, Train Loss 0.1395, Learning Rate 0.0004\n",
      "Validation: 60.5387%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: Train Acc 95.9471%, Train Loss 0.1264, Learning Rate 0.0002\n",
      "Validation: 59.2573%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: Train Acc 96.2379%, Train Loss 0.1243, Learning Rate 0.0000\n",
      "Validation: 58.9697%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: Train Acc 96.4537%, Train Loss 0.1187, Learning Rate 0.0000\n",
      "Validation: 59.8588%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
    "\n",
    "    num_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "       \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.float().to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(x)\n",
    "            del x\n",
    "            loss = criterion(outputs.view(-1,num_classes), y.long().view(-1))\n",
    "\n",
    "        # print(outputs.shape)\n",
    "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
    "        del outputs\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * BATCH)),\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            num_correct=num_correct,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        batch_bar.update() # Update tqdm bar\n",
    "        # break\n",
    "        \n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    print(\"Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
    "        epoch + 1,\n",
    "        epochs,\n",
    "        100 * num_correct / (len(train_dataset)),\n",
    "        float(total_loss / len(train_loader)),\n",
    "        float(optimizer.param_groups[0]['lr'])))\n",
    "    \n",
    "    save(model, epoch)\n",
    "    save(optimizer, epoch, optim=True)\n",
    "    \n",
    "    validate(val_loader, val_dataset, model)\n",
    "    \n",
    "batch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_video_test(filename):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    X.append(df['frames'])\n",
    "    y.append(df['labels'])   \n",
    "    \n",
    "    X = pd.concat(X)    # print(X.head())\n",
    "    X.reset_index(drop=True,inplace=True)\n",
    "    X = X.to_numpy()\n",
    "\n",
    "    \n",
    "    y = pd.concat(y)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    y = y.to_numpy()\n",
    "    \n",
    "    return X, y, df\n",
    "\n",
    "def validate_test(val_loader, val_dataset, model):\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_num_correct = 0\n",
    "    predictions = []\n",
    "    \n",
    "    for i, (vx, vy) in enumerate(val_loader):\n",
    "      \n",
    "        vx = vx.float().to(device)\n",
    "        vy = vy.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(vx)\n",
    "            del vx\n",
    "\n",
    "        preds = torch.argmax(outputs, axis=1)\n",
    "        predictions.append(preds.cpu().detach().numpy())\n",
    "        val_num_correct += int((preds == vy).sum())\n",
    "        del outputs\n",
    "    \n",
    "        # val_num_correct += int((torch.argmax(outputs, axis=1) == vy).sum())\n",
    "        # del outputs\n",
    "        # break\n",
    "    \n",
    "    # print(predictions)\n",
    "    predictions = np.concatenate(predictions)\n",
    "    acc = 100 * val_num_correct / (len(val_dataset))\n",
    "    print(\"Validation: {:.04f}%\".format(acc))\n",
    "    return predictions, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-04T16:18:27\n",
      "165\n",
      "Validation: 81.8182%\n",
      "                      frames  labels  predictions\n",
      "0  2022-04-04T16:18:27_0.npy       2            2\n",
      "1  2022-04-04T16:18:27_1.npy       2            2\n",
      "2  2022-04-04T16:18:27_2.npy       2            2\n",
      "3  2022-04-04T16:18:27_3.npy       2            2\n",
      "4  2022-04-04T16:18:27_4.npy       2            2\n",
      "2022-04-04T16:07:08\n",
      "264\n",
      "Validation: 82.9545%\n",
      "                      frames  labels  predictions\n",
      "0  2022-04-04T16:07:08_0.npy       2            2\n",
      "1  2022-04-04T16:07:08_1.npy       2            2\n",
      "2  2022-04-04T16:07:08_2.npy       2            2\n",
      "3  2022-04-04T16:07:08_3.npy       2            2\n",
      "4  2022-04-04T16:07:08_4.npy       2            2\n",
      "2022-04-04T16:20:59\n",
      "538\n",
      "Validation: 67.8439%\n",
      "                      frames  labels  predictions\n",
      "0  2022-04-04T16:20:59_0.npy       2            2\n",
      "1  2022-04-04T16:20:59_1.npy       2            2\n",
      "2  2022-04-04T16:20:59_2.npy       2            2\n",
      "3  2022-04-04T16:20:59_3.npy       2            2\n",
      "4  2022-04-04T16:20:59_4.npy       2            2\n",
      "2022-04-04T16:12:56\n",
      "230\n",
      "Validation: 82.6087%\n",
      "                      frames  labels  predictions\n",
      "0  2022-04-04T16:12:56_0.npy       2            2\n",
      "1  2022-04-04T16:12:56_1.npy       2            2\n",
      "2  2022-04-04T16:12:56_2.npy       2            2\n",
      "3  2022-04-04T16:12:56_3.npy       2            2\n",
      "4  2022-04-04T16:12:56_4.npy       2            2\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model.load_state_dict(torch.load('./models/attempt_8_frames_resnet34_new_data_diff_split/model_params_00000009.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "for full in f:\n",
    "    fn =  full.split('/')[-1].split('.')[0]\n",
    "    X, y, df = prep_video_test(full)\n",
    "    print(fn)\n",
    "    test_dataset = FrameDataset(X, y, transforms=val_transforms, base_path = PROCESSED_PATH)\n",
    "    val_args = dict(shuffle=False, batch_size=BATCH, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=BATCH, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, **val_args)\n",
    "    print(len(test_dataset))\n",
    "    predictions, acc = validate_test(test_loader, test_dataset, model)\n",
    "    df['predictions'] = predictions\n",
    "    print(df.head())\n",
    "    df.to_csv(\"predictions_{}_{}.csv\".format(fn,acc), index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'../../data_temp/labeled_videos/2022-04-04T16:07:08.csv',\n",
       " '../../data_temp/labeled_videos/2022-04-04T16:12:56.csv',\n",
       " '../../data_temp/labeled_videos/2022-04-04T16:18:27.csv',\n",
       " '../../data_temp/labeled_videos/2022-04-04T16:20:59.csv'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AI_Guide_Dog_Training_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
