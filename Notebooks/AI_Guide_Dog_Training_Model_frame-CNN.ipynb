{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBdKGD39S58T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torchvision  \n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CSFF51DrTFQb"
   },
   "outputs": [],
   "source": [
    "VID_PATH = \"../../data/videos/\"\n",
    "LABEL_PATH = \"../../data/data.npy\"\n",
    "PROCESSED_PATH = \"../../data_temp/processed\"\n",
    "DATA_SAVE_PATH = \"../../data_temp/labeled_videos\"\n",
    "MODELS_PATHS = \"./models\"\n",
    "FRAME_RATE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iUspG4_on3ax"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Preprocess video data.\n",
    "\"\"\"\n",
    "import subprocess\n",
    "import cv2\n",
    "\n",
    "def map_to_multiclass(lab):\n",
    "    if lab == 'LEFT':\n",
    "        return 0\n",
    "    if lab == 'RIGHT':\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "def get_all_files_from_dir(directory):\n",
    "    file_paths = []\n",
    "    print(directory)\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            print(files)\n",
    "            file_paths += [os.path.join(root, x) for x in files]\n",
    "        return sorted(file_paths)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "def get_lab(labels, time):\n",
    "    for row in labels:\n",
    "        if time <= float(row[2]) and time >= float(row[1]):\n",
    "            return row[0]\n",
    "\n",
    "def get_length(filename):\n",
    "    result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                             \"format=duration\", \"-of\",\n",
    "                             \"default=noprint_wrappers=1:nokey=1\", filename],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT)\n",
    "    return float(result.stdout)\n",
    "\n",
    "def inRange(a, b, c, mode = 'full'):\n",
    "    q = round(a/1000 , 3)\n",
    "    if(mode == 'full'):\n",
    "        if (q>=b and q<=c):\n",
    "            return True\n",
    "    else:\n",
    "        if(q>=b):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def process_video(video_file, label_filename):\n",
    "    video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "    labels = pd.read_csv(label_filename, sep='\\t', header=None)\n",
    "    labels[1] = labels[1]-1\n",
    "    labels[2] = labels[2]-1\n",
    "    labels[0] = labels[0].apply(map_to_multiclass)\n",
    "    labels = labels.to_numpy()\n",
    "\n",
    "    vidcap = cv2.VideoCapture(video_file)\n",
    "    # fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    ctr = 0\n",
    "    lbl = 0\n",
    "    \n",
    "    row = labels[lbl]\n",
    "    hasFrames,image = vidcap.read()\n",
    " \n",
    "    while (hasFrames and not inRange(vidcap.get(cv2.CAP_PROP_POS_MSEC), float(row[1]), float(row[2]), mode='half')):\n",
    "        hasFrames,image = vidcap.read()\n",
    "\n",
    "\n",
    "    video_frames = []\n",
    "    video_labels = []\n",
    "    while(True): \n",
    "        try:\n",
    "            while(hasFrames and inRange(vidcap.get(cv2.CAP_PROP_POS_MSEC), float(row[1]),float(row[2]))):\n",
    "                # savefile = {'image': image_to_save, 'label': label_to_save}\n",
    "                save_file_name = video_filename + \"_\" + str(ctr) + \".npy\"\n",
    "                np.save(osp.join(PROCESSED_PATH, save_file_name), image)\n",
    "                if(int(row[0]) == 1):\n",
    "                    fl = 0\n",
    "                elif(int(row[0]) == 0):\n",
    "                    fl = 1\n",
    "                else:\n",
    "                    fl = 2\n",
    "                \n",
    "                save_file_name_flipped = video_filename+\"_flip\" + \"_\" + str(ctr) + \".npy\"\n",
    "                np.save(osp.join(PROCESSED_PATH, save_file_name_flipped),  cv2.flip(image, 1))\n",
    "                \n",
    "                \n",
    "                video_labels.append(int(row[0]))\n",
    "                video_frames.append(save_file_name)\n",
    "                video_labels.append(fl)\n",
    "                video_frames.append(save_file_name_flipped)\n",
    "                \n",
    "                ctr += 1\n",
    "                # for _ in range(2):\n",
    "                hasFrames,image = vidcap.read()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error occured 1: \",e)\n",
    "\n",
    "        if(hasFrames == False or lbl >= len(labels)-1):\n",
    "            break\n",
    "\n",
    "        lbl += 1\n",
    "        row = labels[lbl]\n",
    "    \n",
    "    df = pd.DataFrame({'frames': video_frames, 'labels': video_labels})\n",
    "    df.to_csv(osp.join(DATA_SAVE_PATH,video_filename+\".csv\"), index=None)\n",
    "\n",
    "    print(\"After processing:\")\n",
    "    print(\"Length of labels: \",len(labels))\n",
    "    print(\"Labels utilized: \",lbl)\n",
    "    print(\"Frames labeled: \", len(video_frames))\n",
    "    \n",
    "def preprocess():\n",
    "    for video_filename, label_filename in zip(get_all_files_from_dir(VID_PATH), get_all_files_from_dir(LABEL_PATH)):\n",
    "        process_video(video_filename, label_filename)\n",
    "        print(\"Finished processing \", video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "Wt9bcSU7dReN",
    "outputId": "9d0484db-59c3-4c2c-b515-ab43df7f9a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/Walking_with_compass/\n",
      "['walking_data_3.mp4', 'walking_data_7.mp4', 'walking_data_2.mp4', 'walking_data_4.mp4', 'walking_data_1.mp4', 'walking_data_6.mp4', 'walking_data_5.mp4']\n",
      "../../data/compass/\n",
      "['walking_data_6_compass_label.txt', 'walking_data_2_compass_label.txt', 'walking_data_7_compass_label.txt', 'walking_data_3_compass_label.txt', 'walking_data_4_compass_label.txt', 'walking_data_1_compass_label.txt', 'walking_data_5_compass_label.txt']\n",
      "['walking_data_2_compass_label-checkpoint.txt']\n",
      "After processing:\n",
      "Length of labels:  511\n",
      "Labels utilized:  458\n",
      "Frames labeled:  2782\n",
      "Finished processing  ../../data/Walking_with_compass/walking_data_1.mp4\n",
      "After processing:\n",
      "Length of labels:  405\n",
      "Labels utilized:  404\n",
      "Frames labeled:  2610\n",
      "Finished processing  ../../data/Walking_with_compass/walking_data_2.mp4\n",
      "After processing:\n",
      "Length of labels:  511\n",
      "Labels utilized:  483\n",
      "Frames labeled:  2962\n",
      "Finished processing  ../../data/Walking_with_compass/walking_data_3.mp4\n",
      "After processing:\n",
      "Length of labels:  409\n",
      "Labels utilized:  399\n",
      "Frames labeled:  2788\n",
      "Finished processing  ../../data/Walking_with_compass/walking_data_4.mp4\n",
      "After processing:\n",
      "Length of labels:  439\n",
      "Labels utilized:  438\n",
      "Frames labeled:  2722\n",
      "Finished processing  ../../data/Walking_with_compass/walking_data_5.mp4\n",
      "After processing:\n",
      "Length of labels:  383\n",
      "Labels utilized:  382\n",
      "Frames labeled:  2602\n",
      "Finished processing  ../../data/Walking_with_compass/walking_data_6.mp4\n",
      "After processing:\n",
      "Length of labels:  414\n",
      "Labels utilized:  413\n",
      "Frames labeled:  2596\n",
      "Finished processing  ../../data/Walking_with_compass/walking_data_7.mp4\n"
     ]
    }
   ],
   "source": [
    "### preprocess videos\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e5gsuYg0EDMN"
   },
   "outputs": [],
   "source": [
    "BATCH = 64\n",
    "SEQUENCE_LENGTH = 10\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, index, optim = False):\n",
    "    if not os.path.exists(MODELS_PATHS+'/attempt_6_frames_resnet34'):\n",
    "        os.mkdir(MODELS_PATHS+'/attempt_6_frames_resnet34')\n",
    "    if(optim):\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt_6_frames_resnet34'+'/optimizer_params_{:08d}.pth'.format(index))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt_6_frames_resnet34'+'/model_params_{:08d}.pth'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    \"\"\"\n",
    "    Container for ResNet50 s.t. it can be used for metric learning.\n",
    "    The Network has been broken down to allow for higher modularity, if one wishes\n",
    "    to target specific layers/blocks directly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fixconvs=False, pretrained=True):\n",
    "        super(ResNet34, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=pretrained)\n",
    "        if fixconvs:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.regressor = nn.Linear(self.model.fc.in_features, 3)\n",
    "        self.dropout = torch.nn.Dropout(p=0.05)\n",
    "        self.model = torch.nn.Sequential(*(list(self.model.children())[:-1]))\n",
    "        # model.fc.weight.requires_grad = True\n",
    "        # model.fc.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.regressor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, x, y, transforms, base_path):\n",
    "        self.transforms = transforms\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        # self.seq_len = seq_len\n",
    "        self.base_path = base_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq_filename = self.X[idx]\n",
    "        try:\n",
    "            frame = np.load(osp.join(self.base_path,seq_filename), allow_pickle=True)\n",
    "            frame = (frame - frame.min())/(frame.max() - frame.min())\n",
    "            frame = self.transforms(frame)\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(\"Error occured while loading frame: \", ex)\n",
    "            frame = torch.zeros((CHANNELS, HEIGHT, WIDTH))\n",
    "        \n",
    "        return frame, self.y[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tt_split(data_folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filename in os.listdir(data_folder):\n",
    "        if(filename[-3:]==\"csv\"):\n",
    "            df = pd.read_csv(osp.join(data_folder,filename))\n",
    "            X.append(df['frames'])\n",
    "            y.append(df['labels'])\n",
    "    \n",
    "    \n",
    "    X = pd.concat(X)\n",
    "    X.reset_index(drop=True,inplace=True)\n",
    "    X = X.to_numpy()\n",
    "\n",
    "    \n",
    "    y = pd.concat(y)\n",
    "    y.reset_index(drop=True,inplace=True)\n",
    "    y = y.to_numpy()\n",
    "            \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if(filename[-3:]==\"csv\"):\n",
    "        df = pd.read_csv(osp.join(data_folder,filename))\n",
    "        X.append(df['frames'])\n",
    "        y.append(df['labels'])\n",
    "\n",
    "X = pd.concat(X)\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "X = X.to_numpy()\n",
    "y = pd.concat(y)\n",
    "y.reset_index(drop=True,inplace=True)\n",
    "y = y.to_numpy()\n",
    "\n",
    "\n",
    "test_dataset = FrameDataset(X, y, transforms=val_transforms, base_path = PROCESSED_PATH)\n",
    "test_args = dict(shuffle=False, batch_size=BATCH, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=BATCH, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, **test_args)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX1zg-g3In-9",
    "outputId": "aff9d5b2-0a91-4ecc-b6b2-9beaed1448aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# train_transforms = [ttf.ToTensor(), transforms.Resize((HEIGHT, WIDTH)), transforms.ColorJitter(), transforms.RandomRotation(10), transforms.GaussianBlur(3)]\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_tt_split(DATA_SAVE_PATH)\n",
    "train_dataset = FrameDataset(X_train, y_train, transforms=train_transforms, base_path = PROCESSED_PATH)\n",
    "val_dataset = FrameDataset(X_test, y_test, transforms=val_transforms, base_path = PROCESSED_PATH)\n",
    "\n",
    "\n",
    "train_args = dict(shuffle=True, batch_size=BATCH, num_workers=1, pin_memory=True, drop_last=False) if cuda else dict(shuffle=True, batch_size=BATCH, drop_last=False)\n",
    "train_loader = DataLoader(train_dataset, **train_args)\n",
    "\n",
    "val_args = dict(shuffle=False, batch_size=BATCH, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=BATCH, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, **val_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tgnvcg7a8hHp",
    "outputId": "a4373e9f-1c67-477f-d9a7-4f3088d160cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15249\n",
      "3813\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, val_dataset, model):\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_num_correct = 0\n",
    "   \n",
    "    for i, (vx, vy) in enumerate(val_loader):\n",
    "      \n",
    "        vx = vx.float().to(device)\n",
    "        vy = vy.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(vx)\n",
    "            del vx\n",
    "\n",
    "        val_num_correct += int((torch.argmax(outputs, axis=1) == vy).sum())\n",
    "        del outputs\n",
    "        # break\n",
    "    \n",
    "\n",
    "    print(\"Validation: {:.04f}%\".format(100 * val_num_correct / (len(val_dataset))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sl89a6wJMJEA",
    "outputId": "dbe36a2f-f49a-44f4-e87e-ddb88ab225bd"
   },
   "outputs": [],
   "source": [
    "lr = 0.008 #changed from 0.01\n",
    "epochs = 25\n",
    "lamda = 1e-3  #L2 regularization #changed from 1e-4\n",
    "num_classes = 3\n",
    "convlstm_hidden = 128\n",
    "num_conv_lstm_layers = 2\n",
    "\n",
    "model = ResNet34()\n",
    "model.load_state_dict(torch.load('./models/attempt_6_frames_resnet34/model_params_00000022.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=lamda, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lamda)\n",
    "# optimizer.load_state_dict(torch.load('./models/attempt_6_frames_resnet34/model_params_00000022.pth'))\n",
    "\n",
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] = lr\n",
    "#     g['weight_decay']= lamda\n",
    "    \n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0c275865e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0c275865e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 14.5690%\n"
     ]
    }
   ],
   "source": [
    "# validate(val_loader, val_dataset, model)\n",
    "validate(test_loader, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "dhrrwnCikFAG",
    "outputId": "fb495db9-61a9-4511-b30c-ea4144f8004e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: Train Acc 89.5928%, Train Loss 0.2666, Learning Rate 0.0047\n",
      "Validation: 87.9098%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: Train Acc 90.3731%, Train Loss 0.2439, Learning Rate 0.0047\n",
      "Validation: 68.5812%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: Train Acc 90.6617%, Train Loss 0.2386, Learning Rate 0.0046\n",
      "Validation: 83.1891%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: Train Acc 91.6060%, Train Loss 0.2216, Learning Rate 0.0045\n",
      "Validation: 90.0865%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: Train Acc 92.1962%, Train Loss 0.2077, Learning Rate 0.0043\n",
      "Validation: 82.2974%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: Train Acc 92.6749%, Train Loss 0.1890, Learning Rate 0.0041\n",
      "Validation: 86.7821%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: Train Acc 93.0618%, Train Loss 0.1815, Learning Rate 0.0039\n",
      "Validation: 88.9588%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: Train Acc 93.7898%, Train Loss 0.1647, Learning Rate 0.0036\n",
      "Validation: 90.0341%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: Train Acc 94.2816%, Train Loss 0.1528, Learning Rate 0.0034\n",
      "Validation: 90.4013%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: Train Acc 94.5046%, Train Loss 0.1467, Learning Rate 0.0031\n",
      "Validation: 88.8015%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: Train Acc 95.4227%, Train Loss 0.1261, Learning Rate 0.0028\n",
      "Validation: 91.3454%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: Train Acc 95.5407%, Train Loss 0.1216, Learning Rate 0.0025\n",
      "Validation: 94.9908%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: Train Acc 96.1899%, Train Loss 0.1066, Learning Rate 0.0022\n",
      "Validation: 93.2599%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: Train Acc 96.4719%, Train Loss 0.0990, Learning Rate 0.0019\n",
      "Validation: 90.8471%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(11,epochs):\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
    "\n",
    "    num_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "       \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.float().to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(x)\n",
    "            del x\n",
    "            loss = criterion(outputs.view(-1,num_classes), y.long().view(-1))\n",
    "\n",
    "        # print(outputs.shape)\n",
    "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
    "        del outputs\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * BATCH)),\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            num_correct=num_correct,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        batch_bar.update() # Update tqdm bar\n",
    "        # break\n",
    "        \n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    print(\"Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
    "        epoch + 1,\n",
    "        epochs,\n",
    "        100 * num_correct / (len(train_dataset)),\n",
    "        float(total_loss / len(train_loader)),\n",
    "        float(optimizer.param_groups[0]['lr'])))\n",
    "    \n",
    "    save(model, epoch)\n",
    "    save(optimizer, epoch, optim=True)\n",
    "    \n",
    "    validate(val_loader, val_dataset, model)\n",
    "    \n",
    "batch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AI_Guide_Dog_Training_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
