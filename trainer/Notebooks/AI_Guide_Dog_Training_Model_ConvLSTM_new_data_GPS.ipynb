{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mBdKGD39S58T"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import ffmpeg\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CSFF51DrTFQb"
   },
   "outputs": [],
   "source": [
    "VID_PATH = \"../../data_temp/extracted_videos/\"\n",
    "VID_PATH_OG = \"../../data_temp/videos_new/\"\n",
    "LABEL_FILE = \"../../data/data.npy\"\n",
    "PROCESSED_PATH = \"../../data_temp/processed/\" #frames\n",
    "DATA_SAVE_PATH = \"../../data_temp/labeled_videos/\"  #videos_frame_timestamped\n",
    "MODELS_PATHS = \"./models/\"\n",
    "# LABEL_PATH = '../../data/labels/'\n",
    "FPS = 5\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 2\n",
    "SEQUENCE_LENGTH = 20\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "CHANNELS = 3\n",
    "CONTEXT_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iUspG4_on3ax"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Preprocess video data.\n",
    "\"\"\"\n",
    "def label_map(lab):\n",
    "    if(lab == 0):\n",
    "        return 2\n",
    "    elif(lab == -1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def get_all_files_from_dir(directory, vids = False):\n",
    "    file_paths = []\n",
    "    print(directory)\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            # print(files)\n",
    "            if(vids):\n",
    "                file_paths += [os.path.join(root, x,x+\".mp4\") for x in dirs]\n",
    "            else:\n",
    "                file_paths += [os.path.join(root, x) for x in files]\n",
    "        return sorted(file_paths)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "def turn_high_labeled(vid_context, yy):\n",
    "    start = -10\n",
    "    if(len(vid_context)<10):\n",
    "        start = 0\n",
    "    \n",
    "    for s in vid_context[start:]:\n",
    "        if(s==yy):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_label_pos(vid_pos, offset):\n",
    "    ts = vid_pos + offset\n",
    "    ts = ts - (ts%100)\n",
    "    return ts\n",
    "    \n",
    "def process_video(video_file, labels):\n",
    "    video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "    vidcap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    ctr = 0\n",
    "    video_frames = []\n",
    "    video_context = []\n",
    "    video_labels = []\n",
    "    \n",
    "    hasFrames,image = vidcap.read()\n",
    "    tot_frames = 0\n",
    "    while (hasFrames):\n",
    "        tot_frames += 1\n",
    "        save_file_name = video_filename + \"_\" + str(ctr) + \".npy\"\n",
    "        \n",
    "        vid_pos = vidcap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        label_ts = get_label_pos(vid_pos,1000)\n",
    "        if(label_ts not in labels.keys()):\n",
    "            print(label_ts)\n",
    "            hasFrames,image = vidcap.read()\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, (WIDTH, HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "        np.save(osp.join(PROCESSED_PATH, save_file_name), image)  \n",
    "        video_frames.append(save_file_name)\n",
    "\n",
    "        label = labels[label_ts]\n",
    "        video_labels.append(label)\n",
    "        \n",
    "        context_ts = get_label_pos(vid_pos,3000) + 100\n",
    "        limit_ts = get_label_pos(vid_pos,1500)\n",
    "        \n",
    "        if(context_ts in labels.keys() and not turn_high_labeled(video_context,labels[context_ts]) and labels[limit_ts]!=labels[context_ts]):\n",
    "            video_context.append(labels[context_ts])\n",
    "        else:\n",
    "            video_context.append(2) #Default: FRONT == 2\n",
    "        \n",
    "        \n",
    "        hasFrames,image = vidcap.read()\n",
    "        ctr += 1\n",
    "    \n",
    "    print(\"Actual labels: \", labels)\n",
    "    print(\"Labels: \", video_labels)\n",
    "    print(\"Context: \", video_context)\n",
    "    \n",
    "    df = pd.DataFrame({'frames': video_frames, 'gps': video_context, 'labels': video_labels})\n",
    "    df.to_csv(osp.join(DATA_SAVE_PATH,video_filename+\".csv\"), index=None)\n",
    "\n",
    "    print(\"After processing:\")\n",
    "    print(\"Total frames: \",tot_frames)\n",
    "    print(\"Number of frames labelled: \", ctr)\n",
    "    \n",
    "def preprocess():\n",
    "    f = np.load(LABEL_FILE, allow_pickle = True)\n",
    "    # print(f.keys())\n",
    "    for video_file in get_all_files_from_dir(VID_PATH):\n",
    "        video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "        print(video_filename)\n",
    "        # if(video_filename+\".csv\" not in os.listdir(DATA_SAVE_PATH)):\n",
    "        labels = f[video_filename]['Sensor']['direction_label']['direction']\n",
    "\n",
    "        for k,v in labels.items():\n",
    "            labels[k] = label_map(v)\n",
    "\n",
    "        process_video(video_file, labels)\n",
    "        print(\"Finished processing \", video_file)\n",
    "\n",
    "def process_videos(vid_path = VID_PATH_OG):\n",
    "    fp = get_all_files_from_dir(vid_path, vids=True)\n",
    "    print(fp)\n",
    "    for fl in fp:\n",
    "        video_filename = fl.split('/')[-1]\n",
    "        if(video_filename not in os.listdir(VID_PATH)):\n",
    "            ffmpeg.input(fl).filter('fps', fps=FPS, round='up').output(VID_PATH+video_filename).run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d_znptq-bXNz"
   },
   "outputs": [],
   "source": [
    "# process_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Wt9bcSU7dReN"
   },
   "outputs": [],
   "source": [
    "### preprocess videos\n",
    "# preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L5SGMeoqFj3X"
   },
   "outputs": [],
   "source": [
    "def labelCount(label):\n",
    "    label_count = [0]*(n_classes)\n",
    "    for lab in label:\n",
    "        label_count[lab] += 1\n",
    "    return label_count\n",
    "\n",
    "def sampler_(dataset_labels):\n",
    "    dataset_counts = labelCount(dataset_labels)\n",
    "    print(dataset_counts)\n",
    "    num_samples = sum(dataset_counts)\n",
    "    class_weights = [num_samples/i for i in dataset_counts]\n",
    "    weights = [class_weights[y] for y in dataset_labels]\n",
    "    sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    return sampler\n",
    "\n",
    "def sanity_check(gps, y):\n",
    "    if(y!=2):\n",
    "        for i in gps:\n",
    "            if(i==y):\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def good_data_check(ys):\n",
    "    for i in range(7):\n",
    "        if(ys[i]!=2):\n",
    "            return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IIFM_Mc9Tjnz"
   },
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, files, transforms, seq_len, base_path):\n",
    "        self.transforms = transforms\n",
    "        self.files = files\n",
    "        self.seq_len = seq_len\n",
    "        self.base_path = base_path\n",
    "        X = []\n",
    "        context = []\n",
    "        y = []\n",
    "        for f in files:\n",
    "            df = pd.read_csv(f)\n",
    "            for i in range(len(df)-self.seq_len):\n",
    "                cand_x = df['frames'][i:i+self.seq_len].to_numpy()\n",
    "                cand_gps = df['gps'][i:i+self.seq_len].to_numpy()\n",
    "                cand_y = df['labels'][i+self.seq_len-1]\n",
    "                if(sanity_check(cand_gps, cand_y) and good_data_check(df['labels'][i:i+self.seq_len].to_numpy())):\n",
    "                    X.append(cand_x)\n",
    "                    context.append(cand_gps)\n",
    "                    y.append(cand_y)\n",
    "        \n",
    "        # print(\"Y\", y)\n",
    "\n",
    "        self.X = np.stack(X, axis = 0)\n",
    "        self.context = np.stack(context, axis = 0)\n",
    "        self.y = np.array(y)\n",
    "        print(len(self.y))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq_filename = self.X[idx]\n",
    "        context = self.context[idx]\n",
    "        video = torch.FloatTensor(self.seq_len, CHANNELS+CONTEXT_CHANNELS, HEIGHT, WIDTH)\n",
    "        for e,filename_context in enumerate(zip(seq_filename,context)):\n",
    "            filename, cont = filename_context\n",
    "            try:\n",
    "                frame = np.load(osp.join(self.base_path,filename), allow_pickle=True)\n",
    "                frame = (frame - frame.min())/(frame.max() - frame.min())\n",
    "                frame = self.transforms(frame)\n",
    "\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                frame = torch.zeros((CHANNELS, HEIGHT, WIDTH))\n",
    "\n",
    "            context_tensor = torch.full((CONTEXT_CHANNELS, HEIGHT, WIDTH), cont)\n",
    "            context_frame = torch.cat((context_tensor, frame), dim = 0)\n",
    "            video[e,:,:,:] = context_frame\n",
    "          \n",
    "        # return video, torch.LongTensor(self.y[idx])\n",
    "        return video, self.y[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_YaGV5rWnuLO"
   },
   "outputs": [],
   "source": [
    "def make_tt_split(data_folder, seq_len):\n",
    "    files = []\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if(filename[-3:]==\"csv\"):\n",
    "            files.append(osp.join(data_folder,filename))\n",
    "    \n",
    "    random.shuffle(files)\n",
    "    \n",
    "    ts = int(len(files) * 0.25)\n",
    "    test_files = files[:ts]\n",
    "    train_files = files[ts:]\n",
    "    print(\"Test files \",test_files)\n",
    "    return train_files, test_files\n",
    "\n",
    "\n",
    "def use_tt_split(data_folder, lst):\n",
    "    files = []\n",
    "    for filename in os.listdir(data_folder):\n",
    "        filename = osp.join(data_folder,filename)\n",
    "        if(filename[-3:]==\"csv\" and filename not in lst):\n",
    "            files.append(filename)\n",
    "    print(files)\n",
    "    return files, lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX1zg-g3In-9",
    "outputId": "aff9d5b2-0a91-4ecc-b6b2-9beaed1448aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['../../data_temp/labeled_videos/2022-04-04T18:47:26.csv', '../../data_temp/labeled_videos/2022-04-04T18:48:45.csv', '../../data_temp/labeled_videos/2022-04-04T18:58:12.csv', '../../data_temp/labeled_videos/2022-04-04T18:59:05.csv', '../../data_temp/labeled_videos/2022-04-04T19:04:56.csv', '../../data_temp/labeled_videos/2022-04-04T19:06:29.csv', '../../data_temp/labeled_videos/2022-04-04T19:07:55.csv', '../../data_temp/labeled_videos/2022-04-04T19:09:43.csv', '../../data_temp/labeled_videos/2022-04-04T19:10:28.csv', '../../data_temp/labeled_videos/2022-04-04T19:16:45.csv', '../../data_temp/labeled_videos/2022-04-04T19:17:50.csv', '../../data_temp/labeled_videos/2022-04-04T19:18:52.csv', '../../data_temp/labeled_videos/2022-04-04T19:21:41.csv', '../../data_temp/labeled_videos/2022-04-04T19:22:45.csv', '../../data_temp/labeled_videos/2022-04-04T19:23:24.csv', '../../data_temp/labeled_videos/2022-04-04T19:28:21.csv', '../../data_temp/labeled_videos/2022-04-04T19:28:40.csv', '../../data_temp/labeled_videos/2022-04-04T19:28:57.csv']\n",
      "1265\n",
      "470\n",
      "[206, 326, 733]\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# train_transforms = [ttf.ToTensor(), transforms.Resize((HEIGHT, WIDTH)), transforms.ColorJitter(), transforms.RandomRotation(10), transforms.GaussianBlur(3)]\n",
    "# train_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "# val_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "test_files = ['../../data_temp/labeled_videos/2022-04-04T19:01:16.csv', '../../data_temp/labeled_videos/2022-04-04T19:02:28.csv', '../../data_temp/labeled_videos/2022-04-04T18:41:15.csv', '../../data_temp/labeled_videos/2022-04-04T19:19:33.csv', '../../data_temp/labeled_videos/2022-04-04T19:24:10.csv']\n",
    "train_files, test_files = use_tt_split(DATA_SAVE_PATH, test_files)\n",
    "# train_files, test_files = make_tt_split(DATA_SAVE_PATH, seq_len = SEQUENCE_LENGTH)\n",
    "\n",
    "train_dataset = VideoDataset(train_files, transforms=train_transforms, seq_len = SEQUENCE_LENGTH, base_path = PROCESSED_PATH)\n",
    "val_dataset = VideoDataset(test_files, transforms=val_transforms, seq_len = SEQUENCE_LENGTH, base_path = PROCESSED_PATH)\n",
    "\n",
    "sampler = sampler_(train_dataset.y)\n",
    "\n",
    "train_args = dict(batch_size=BATCH, sampler = sampler, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(batch_size=BATCH, drop_last=False)\n",
    "train_loader = DataLoader(train_dataset, **train_args)\n",
    "\n",
    "val_args = dict(shuffle=False, batch_size=BATCH, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=BATCH, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, **val_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tgnvcg7a8hHp",
    "outputId": "a4373e9f-1c67-477f-d9a7-4f3088d160cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "b5YXDoksGA_i"
   },
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "        \n",
    "        for mod in self.modules():\n",
    "            if isinstance(mod, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(mod.weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "            # elif isinstance(mod, nn.BatchNorm2d):\n",
    "            #     nn.init.constant_(mod.weight, 1)\n",
    "            #     nn.init.constant_(mod.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        input_dim: Number of channels in input\n",
    "        hidden_dim: Number of hidden channels\n",
    "        kernel_size: Size of kernel in convolutions\n",
    "        num_layers: Number of LSTM layers stacked on each other\n",
    "        batch_first: Whether or not dimension 0 is the batch or not\n",
    "        bias: Bias or no bias in Convolution\n",
    "        return_all_layers: Return the list of computations for all layers\n",
    "        Note: Will do same padding.\n",
    "    Input:\n",
    "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
    "    Output:\n",
    "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "            0 - layer_output_list is the list of lists of length T of each output\n",
    "            1 - last_state_list is the list of last states\n",
    "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
    "    Example:\n",
    "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
    "        >> _, last_states = convlstm(x)\n",
    "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo\n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, _, _, h, w = input_tensor.size()\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b,\n",
    "                                             image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h) #[batch_size, self.hidden_dim, height, width]\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1) #[batch_size,t,self.hidden_dim, height, width]\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9_s93Au3Rk-F"
   },
   "outputs": [],
   "source": [
    "class ConvLSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False, num_classes = 3):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.convlstm = ConvLSTM(input_dim, hidden_dim, kernel_size, num_layers,batch_first, bias, return_all_layers)\n",
    "        self.linear = nn.Linear(hidden_dim * HEIGHT * WIDTH, num_classes)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "      x,_ = self.convlstm(input_tensor)\n",
    "      x = x[0]\n",
    "      # print(x.shape)  # torch.Size([2, 8, 128, 256, 256]) batch, t, channels, h, w\n",
    "      x = x[:,-1,:,:,:]  #pick the last timestamp output\n",
    "      # print(x.shape)\n",
    "      x = torch.flatten(x, start_dim=1) # change from start_dim=2 after adding the above line\n",
    "      # print(x.shape)  \t# torch.Size([2,8388608])\n",
    "\n",
    "      x = self.linear(x) #op: [batch, num_classes] \n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UrI2yNxqbvvI"
   },
   "outputs": [],
   "source": [
    "def save(model, index, acc, optim = False):\n",
    "    if not os.path.exists(MODELS_PATHS+'/attempt11_1sec_prior_convlstm_new_data_3sec_prior_gps'):\n",
    "        os.mkdir(MODELS_PATHS+'/attempt11_1sec_prior_convlstm_new_data_3sec_prior_gps')\n",
    "    if(optim):\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt11_1sec_prior_convlstm_new_data_3sec_prior_gps'+'/optimizer_params_{:08d}_acc={}.pth'.format(index,acc))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), MODELS_PATHS+'/attempt11_1sec_prior_convlstm_new_data_3sec_prior_gps'+'/model_params_{:08d}_acc={}.pth'.format(index,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sl89a6wJMJEA",
    "outputId": "dbe36a2f-f49a-44f4-e87e-ddb88ab225bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTMModel(\n",
      "  (convlstm): ConvLSTM(\n",
      "    (cell_list): ModuleList(\n",
      "      (0): ConvLSTMCell(\n",
      "        (conv): Conv2d(260, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=4194304, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 0.008 #changed from 0.01\n",
    "epochs = 50\n",
    "lamda = 1e-2  #L2 regularization #changed from 1e-4\n",
    "num_classes = 3\n",
    "convlstm_hidden = 256\n",
    "num_conv_lstm_layers = 1\n",
    "\n",
    "model = ConvLSTMModel(CHANNELS+CONTEXT_CHANNELS,convlstm_hidden,(3,3),num_conv_lstm_layers,batch_first=True)\n",
    "model.load_state_dict(torch.load('./models/attempt11_1sec_prior_convlstm_new_data_3sec_prior_gps/model_params_00000006_acc=50.0.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=lamda, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lamda)\n",
    "optimizer.load_state_dict(torch.load('./models/attempt11_1sec_prior_convlstm_new_data_3sec_prior_gps/optimizer_params_00000006_acc=50.0.pth'))\n",
    "\n",
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] = lr\n",
    "#     g['weight_decay']= lamda\n",
    "    \n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "dhrrwnCikFAG",
    "outputId": "fb495db9-61a9-4511-b30c-ea4144f8004e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                            | 0/633 [00:01<?, ?it/s, acc=0.0000%, loss=10996.0000, lr=0.0076, num_correct=0]/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: Train Acc 59.3676%, Train Loss 2698.5924, Learning Rate 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:40,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 19.3617%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: Train Acc 63.4783%, Train Loss 1578.0679, Learning Rate 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 53.1915%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: Train Acc 59.7628%, Train Loss 2005.5028, Learning Rate 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 39.1489%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: Train Acc 66.5613%, Train Loss 1930.3819, Learning Rate 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:40,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 53.8298%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: Train Acc 77.7075%, Train Loss 956.6614, Learning Rate 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 50.2128%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: Train Acc 74.6245%, Train Loss 988.0241, Learning Rate 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 40.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: Train Acc 81.6601%, Train Loss 643.0930, Learning Rate 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:42,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 36.8085%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: Train Acc 79.6838%, Train Loss 619.8096, Learning Rate 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 37.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: Train Acc 77.3913%, Train Loss 649.9733, Learning Rate 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:42,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 42.3404%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: Train Acc 81.1067%, Train Loss 485.9408, Learning Rate 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:40,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 35.7447%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: Train Acc 77.7866%, Train Loss 708.3089, Learning Rate 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 44.0426%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: Train Acc 75.1779%, Train Loss 830.3116, Learning Rate 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:39,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 28.9362%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: Train Acc 61.8182%, Train Loss 1683.7948, Learning Rate 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 43.1915%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: Train Acc 73.9921%, Train Loss 751.1762, Learning Rate 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 44.8936%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: Train Acc 78.7352%, Train Loss 481.1679, Learning Rate 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:37,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 45.7447%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: Train Acc 81.4229%, Train Loss 475.5321, Learning Rate 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 41.2766%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: Train Acc 83.1621%, Train Loss 356.8769, Learning Rate 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:39,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 47.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: Train Acc 83.6364%, Train Loss 314.4207, Learning Rate 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:37,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 41.7021%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: Train Acc 67.5889%, Train Loss 1181.9481, Learning Rate 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 47.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: Train Acc 76.5217%, Train Loss 606.6721, Learning Rate 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:39,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 27.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: Train Acc 83.7154%, Train Loss 383.3983, Learning Rate 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 54.2553%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: Train Acc 80.9486%, Train Loss 379.0868, Learning Rate 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:37,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 44.4681%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: Train Acc 78.1818%, Train Loss 488.6598, Learning Rate 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:37,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 46.8085%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: Train Acc 79.2095%, Train Loss 460.2602, Learning Rate 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 48.2979%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: Train Acc 83.2411%, Train Loss 306.6646, Learning Rate 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 32.3404%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: Train Acc 82.6087%, Train Loss 406.6773, Learning Rate 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 36.5957%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: Train Acc 87.7470%, Train Loss 210.7678, Learning Rate 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 51.2766%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: Train Acc 86.4822%, Train Loss 225.4317, Learning Rate 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:37,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 53.6170%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: Train Acc 87.7470%, Train Loss 214.9265, Learning Rate 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:40,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 40.8511%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: Train Acc 84.0316%, Train Loss 213.3020, Learning Rate 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 39.3617%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: Train Acc 88.3004%, Train Loss 188.9890, Learning Rate 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 47.2340%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: Train Acc 89.2490%, Train Loss 133.0325, Learning Rate 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:40,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 48.7234%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: Train Acc 88.7747%, Train Loss 120.8571, Learning Rate 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:34,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 38.9362%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: Train Acc 89.5652%, Train Loss 114.9701, Learning Rate 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:40,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 47.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: Train Acc 94.7826%, Train Loss 45.6650, Learning Rate 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 40.2128%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: Train Acc 93.8340%, Train Loss 57.7543, Learning Rate 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 43.8298%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: Train Acc 93.4387%, Train Loss 60.8694, Learning Rate 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:40,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 37.6596%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: Train Acc 95.2569%, Train Loss 28.7116, Learning Rate 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 47.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: Train Acc 95.0198%, Train Loss 28.9360, Learning Rate 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:39,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 37.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: Train Acc 96.6008%, Train Loss 21.7528, Learning Rate 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 47.4468%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: Train Acc 98.3399%, Train Loss 9.4489, Learning Rate 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 45.5319%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: Train Acc 98.2609%, Train Loss 7.6866, Learning Rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:38,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 45.3191%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: Train Acc 97.8656%, Train Loss 5.8826, Learning Rate 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:41,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 44.2553%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(7,epochs):\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
    "\n",
    "    num_correct = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "       \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.float().to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(x)\n",
    "            del x\n",
    "            # loss = criterion(outputs.view(-1,num_classes), y.long().view(-1))\n",
    "            loss = criterion(outputs, y.long())\n",
    "\n",
    "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
    "        del outputs\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * BATCH)),\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            num_correct=num_correct,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        batch_bar.update() # Update tqdm bar\n",
    "        \n",
    "\n",
    "    batch_bar.close()\n",
    "    acc = 100 * num_correct / (len(train_dataset))\n",
    "    print(\"Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
    "        epoch + 1,\n",
    "        epochs,\n",
    "        acc,\n",
    "        float(total_loss / len(train_loader)),\n",
    "        float(optimizer.param_groups[0]['lr'])))\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_num_correct = 0\n",
    "    \n",
    "    for i, (vx, vy) in tqdm(enumerate(val_loader)):\n",
    "      \n",
    "      vx = vx.to(device)\n",
    "      vy = vy.to(device)\n",
    "\n",
    "      with torch.no_grad():\n",
    "          outputs = model(vx)\n",
    "          del vx\n",
    "\n",
    "      val_num_correct += int((torch.argmax(outputs, axis=1) == vy).sum())\n",
    "      del outputs\n",
    "\n",
    "    acc = 100 * val_num_correct / (len(val_dataset))\n",
    "    print(\"Validation: {:.04f}%\".format(acc))\n",
    "    \n",
    "    \n",
    "    save(model, epoch, acc)\n",
    "    save(optimizer, epoch,acc, optim=True)\n",
    "    \n",
    "    \n",
    "batch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpmjDEzInuLU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def prep_test_data(filename, seq_len):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename)\n",
    "    print(len(df))\n",
    "    frames = df['frames'].to_numpy()\n",
    "    labels = df['labels'].to_numpy()\n",
    "    for i in range(0,len(df)-seq_len, seq_len):\n",
    "        X.append(frames[i:i+seq_len])\n",
    "        y.append(labels[i:i+seq_len])\n",
    "   \n",
    "    X = np.stack(X, axis = 0)\n",
    "    y = np.stack(y, axis = 0)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    a,b = X.shape\n",
    "    return X,y, df[:a*b]\n",
    "\n",
    "def validate_test(test_loader, test_dataset, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    val_num_correct = 0\n",
    "\n",
    "    \n",
    "    for i, (vx, vy) in tqdm(enumerate(test_loader)):\n",
    "\n",
    "        vx = vx.to(device)\n",
    "        vy = vy.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(vx)\n",
    "            del vx\n",
    "\n",
    "        preds = torch.argmax(outputs, axis=2)\n",
    "        # print(preds.shape)\n",
    "        predictions.append(preds.cpu().detach().numpy())\n",
    "        val_num_correct += int((preds == vy).sum())\n",
    "        del outputs\n",
    "\n",
    "        # val_num_correct += int((torch.argmax(outputs, axis=2) == vy).sum())\n",
    "        # del outputs\n",
    "    print(len(predictions))\n",
    "    predictions = np.concatenate(predictions, axis = 0)\n",
    "    print(predictions.shape)\n",
    "    predictions = predictions.flatten()\n",
    "    print(predictions.shape)\n",
    "    acc = (100 * val_num_correct / (len(test_dataset) * SEQUENCE_LENGTH))\n",
    "    print(\"Validation: {:.04f}%\".format(acc))\n",
    "    return predictions, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xm8Gnj3gnuLU",
    "outputId": "69f2d742-51a7-4412-9547-b5c024ad45b1"
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "convlstm_hidden = 128\n",
    "num_conv_lstm_layers = 2\n",
    "BATCH = 2\n",
    "\n",
    "model = ConvLSTMModel(CHANNELS,convlstm_hidden,(3,3),num_conv_lstm_layers,True)\n",
    "model.load_state_dict(torch.load('./models/attempt3_1sec_prior/model_params_00000013.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# train_transforms = [ttf.ToTensor(), transforms.Resize((HEIGHT, WIDTH)), transforms.ColorJitter(), transforms.RandomRotation(10), transforms.GaussianBlur(3)]\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((HEIGHT, WIDTH))])\n",
    "# f = {'../../data/videos/walking_data_2.csv',\n",
    "#  '../../data/videos/walking_data_5.csv'}\n",
    "\n",
    "for f in os.listdir(DATA_SAVE_PATH):    \n",
    "    X, y, df = prep_test_data(osp.join(DATA_SAVE_PATH,f), seq_len = SEQUENCE_LENGTH)\n",
    "    test_dataset = VideoDataset(X, y, transforms=val_transforms, seq_len = SEQUENCE_LENGTH, base_path = \"../../data_temp/processed/\")\n",
    "\n",
    "    test_args = dict(shuffle=False, batch_size=BATCH, num_workers=2, pin_memory=True, drop_last=False) if cuda else dict(shuffle=False, batch_size=BATCH, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, **test_args)\n",
    "    \n",
    "    predictions, acc = validate_test(test_loader, test_dataset, model)\n",
    "    df['predictions'] = predictions\n",
    "    print(df.head())\n",
    "    df.to_csv(\"convlstm_predictions_{}_{}.csv\".format(fn,acc), index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIv68vqKnuLV"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#   Preprocess video data.\n",
    "# \"\"\"\n",
    "# def label_map(lab):\n",
    "#     if(lab == 0):\n",
    "#         return 2\n",
    "#     elif(lab == -1):\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "    \n",
    "# def get_all_files_from_dir(directory, vids = False):\n",
    "#     file_paths = []\n",
    "#     print(directory)\n",
    "#     try:\n",
    "#         for root, dirs, files in os.walk(directory):\n",
    "#             # print(files)\n",
    "#             if(vids):\n",
    "#                 file_paths += [os.path.join(root, x,x+\".mp4\") for x in dirs]\n",
    "#             else:\n",
    "#                 file_paths += [os.path.join(root, x) for x in files]\n",
    "#         return sorted(file_paths)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "    \n",
    "# def turn_high_labeled(vid_context, yy):\n",
    "#     start = -10\n",
    "#     if(len(vid_context)<10):\n",
    "#         start = 0\n",
    "    \n",
    "#     for s in vid_context[start:]:\n",
    "#         if(s==yy):\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# def process_video(video_file, labels):\n",
    "#     video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "#     vidcap = cv2.VideoCapture(video_file)\n",
    "\n",
    "#     ctr = 0\n",
    "#     video_frames = []\n",
    "#     video_context = []\n",
    "#     video_labels = []\n",
    "    \n",
    "#     hasFrames,image = vidcap.read()\n",
    "#     tot_frames = 0\n",
    "#     while (hasFrames):\n",
    "#         tot_frames += 1\n",
    "#         save_file_name = video_filename + \"_\" + str(ctr) + \".npy\"\n",
    "        \n",
    "#         vid_pos = vidcap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#         label_ts = vid_pos + 1000 #take 1 sec ahead labels \n",
    "#         label_ts = label_ts - (label_ts%100)\n",
    "#         if(label_ts not in labels.keys()):\n",
    "#             print(label_ts)\n",
    "#             hasFrames,image = vidcap.read()\n",
    "#             continue\n",
    "\n",
    "#         image = cv2.resize(image, (WIDTH, HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "#         np.save(osp.join(PROCESSED_PATH, save_file_name), image)  \n",
    "#         video_frames.append(save_file_name)\n",
    "\n",
    "#         label = labels[label_ts]\n",
    "#         video_labels.append(label)\n",
    "        \n",
    "#         context_ts = vid_pos + 3000 #take 1 sec ahead labels \n",
    "#         context_ts = context_ts - (context_ts%100) + 100\n",
    "        \n",
    "#         if(context_ts in labels.keys() and not turn_high_labeled(video_context,labels[context_ts])):\n",
    "#             video_context.append(labels[context_ts])\n",
    "#         else:\n",
    "#             video_context.append(2) #Default: FRONT == 2\n",
    "        \n",
    "        \n",
    "#         hasFrames,image = vidcap.read()\n",
    "#         ctr += 1\n",
    "        \n",
    "#     df = pd.DataFrame({'frames': video_frames, 'gps': video_context, 'labels': video_labels})\n",
    "#     df.to_csv(osp.join(DATA_SAVE_PATH,video_filename+\".csv\"), index=None)\n",
    "\n",
    "#     print(\"After processing:\")\n",
    "#     print(\"Total frames: \",tot_frames)\n",
    "#     print(\"Number of frames labelled: \", ctr)\n",
    "    \n",
    "# def preprocess():\n",
    "#     f = np.load(LABEL_FILE, allow_pickle = True)\n",
    "#     # print(f.keys())\n",
    "#     for video_file in get_all_files_from_dir(VID_PATH):\n",
    "#         video_filename = video_file.split('/')[-1].split('.')[0]\n",
    "#         print(video_filename)\n",
    "#         if(video_filename+\".csv\" not in os.listdir(DATA_SAVE_PATH)):\n",
    "#             labels = f[video_filename]['Sensor']['direction_label']['direction']\n",
    "           \n",
    "#             for k,v in labels.items():\n",
    "#                 labels[k] = label_map(v)\n",
    "                \n",
    "#             process_video(video_file, labels)\n",
    "#             print(\"Finished processing \", video_file)\n",
    "        \n",
    "# def process_videos(vid_path = VID_PATH_OG):\n",
    "#     fp = get_all_files_from_dir(vid_path, vids=True)\n",
    "#     print(fp)\n",
    "#     for fl in fp:\n",
    "#         video_filename = fl.split('/')[-1]\n",
    "#         if(video_filename not in os.listdir(VID_PATH)):\n",
    "#             ffmpeg.input(fl).filter('fps', fps=FPS, round='up').output(VID_PATH+video_filename).run() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AI_Guide_Dog_Training_Model_ConvLSTM-new_data_GPS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
